{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# import requests\n",
    "\n",
    "# url = 'https://www.ifsc-climbing.org/index.php/2-uncategorised/281-member-federations'\n",
    "\n",
    "# data = requests.get(url)\n",
    "\n",
    "# print(data.text)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from IPython.display import Image\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "'''\n",
    "--Imports--\n",
    "BeautifulSoup is used to parse through Html data.\n",
    "Requests gets us the data from the webpage.\n",
    "csv is used to output the data we get into a csv.\n",
    "\n",
    "'''\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import csv\n",
    "# import lxml.html\n",
    "\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# This is standard in every website you will do this. Request and use BeautifulSoup to \"Soupify\". \n",
    "# The output is the code for the whole page\n",
    "\n",
    "url = 'https://www.ifsc-climbing.org/index.php/2-uncategorised/281-member-federations'\n",
    "# agent = {\"User-Agent\":'Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.115 Safari/537.36'}\n",
    "headers = {\n",
    "     \"User-Agent\":'Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.115 Safari/537.36',\n",
    "}\n",
    "req = requests.get(url,headers=headers)\n",
    "soup = bs(req.content)\n",
    "# soup = bs(req.content,'lxml')\n",
    "# soup.body.find_all('div')\n",
    "soup"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cards=soup.find_all(class_='uk-card')\n",
    "# x[0].find(class_='uk-card-title').text\n",
    "#find_city\n",
    "def find_city():\n",
    "    all_countries = []\n",
    "\n",
    "    for i in range(len(cards)):\n",
    "\n",
    "        all_countries.append(cards[i].find(class_='uk-card-title').text)\n",
    "    \n",
    "    return all_countries\n",
    "\n",
    "find_city()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import re \n",
    "cards=soup.find_all(class_='uk-card')\n",
    "all_names = []\n",
    "def find_name():\n",
    "\n",
    "    for x in range(len(cards)):\n",
    "        if cards[x].find(\"div\",{\"class\":\"uk-text-meta\"}) != None:\n",
    "\n",
    "                text =(cards[x].find(\"div\",{\"class\":\"uk-text-meta\"}).text.strip())\n",
    "                all_names.append(re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", text))\n",
    "       \n",
    "    \n",
    "    print(all_names)    \n",
    "\n",
    "find_name()\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "source": [
    "cards=soup.find_all(class_='uk-card')\n",
    "all_mails=[]\n",
    "def find_email():\n",
    "    \n",
    "    for y in range(len(cards)):\n",
    "        if cards[y].find(href=True) != None:\n",
    "            # print(cards[y])\n",
    "            all_data = cards[y].find(href=True).text\n",
    "            if '@' in all_data:\n",
    "                all_mails.append(all_data)\n",
    "\n",
    "          \n",
    "find_email()\n",
    "print(all_mails)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "# cards=soup.find_all(class_='uk-card')\n",
    "# all_websites=[]\n",
    "# def find_website():\n",
    "#     for j in range(len(cards)):\n",
    "#         if cards[j].find(class_='uk-button-text') != None:\n",
    "#             all_data = cards[j].find(class_='uk-button-text').text\n",
    "#             # for data in all_data:\n",
    "#             if soup.find('a'):\n",
    "#                 all_websites.append(all_data)\n",
    "#                 print(all_data)\n",
    "\n",
    "#                 return soup.find('a')['href']\n",
    "#             # return None\n",
    "# find_website()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# cards=soup.find_all(class_='uk-card')\n",
    "# print(cards)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}